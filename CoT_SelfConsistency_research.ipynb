{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "mount_file_id": "1J_2EneGCALTG0vG-I-Tzwif_HnBq5V7k",
      "authorship_tag": "ABX9TyOKRK6mlvBYcazisl78lfw1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/M1croZavr/CoTResearch/blob/master/CoT_SelfConsistency_research.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Установка и импортирование необходимых библиотек и git clone репозитория с необходимым кодом и данными. В случае запуска с petals, необходимо раскомментировать соответствующие ячейки."
      ],
      "metadata": {
        "id": "THdRTvEhacxv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9PnfvS_aPQWX"
      },
      "outputs": [],
      "source": [
        "# %pip install -q petals"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/M1croZavr/CoTResearch.git"
      ],
      "metadata": {
        "id": "OYIT9JN2ZfkN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version"
      ],
      "metadata": {
        "id": "IjH5Z93JjAsQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "\n",
        "drive.mount('./drive')"
      ],
      "metadata": {
        "id": "-_nc-l3To6Df"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "import time\n",
        "import json\n",
        "import shutil\n",
        "import requests\n",
        "from pathlib import Path\n",
        "from tqdm.auto import tqdm\n",
        "# from transformers import BloomTokenizerFast, set_seed\n",
        "# from petals import DistributedBloomForCausalLM\n",
        "from CoTResearch.data_preprocessing import FormattedPrompts, FormattedInputs\n",
        "from CoTResearch.data_postprocessing import AnswersList"
      ],
      "metadata": {
        "id": "VMx-JO37PTJJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f'Running device: {DEVICE}')"
      ],
      "metadata": {
        "id": "c8KkQZwvZQLE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Загрузка модели BLOOM из petals"
      ],
      "metadata": {
        "id": "dOso3I-OazHz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# MODEL_NAME = \"bigscience/bloom-petals\"\n",
        "# tokenizer = BloomTokenizerFast.from_pretrained(MODEL_NAME)\n",
        "# model = DistributedBloomForCausalLM.from_pretrained(MODEL_NAME)\n",
        "# model = model.to(DEVICE)"
      ],
      "metadata": {
        "id": "zF02XH07PTNs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Пример одного prompt c 2 CoT"
      ],
      "metadata": {
        "id": "fgd6jYlXa6yE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example_prompts = FormattedPrompts(\n",
        "    data_path=Path('CoTResearch/GSM8K_data/train_data.jsonl'),\n",
        "    n_exemplars=2, \n",
        "    random_seed=123\n",
        "    )\n",
        "example_prompts.sample_prompts()\n",
        "example_inputs = FormattedInputs(example_prompts)\n",
        "\n",
        "\n",
        "with open(Path('CoTResearch/GSM8K_data/test_data.jsonl')) as file:\n",
        "    example_prompt = example_inputs.sample_input(file.readline())\n",
        "print(example_prompt)"
      ],
      "metadata": {
        "id": "I34HjBP3Zqyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Инициализируем объект форматированных prompts и делаю сэмплинг из тренировочного набора. Для проведения экспериментов устанавливаю некоторый seed для формирования экземпляров prompts и выбора тестовых вопросов из GSM8K"
      ],
      "metadata": {
        "id": "IMLDkq4RbFB3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PROMPTS_SET_SEED = 14799\n",
        "TEST_SPLIT_SEED = 77777\n",
        "prompts = FormattedPrompts(\n",
        "    data_path=Path('CoTResearch/GSM8K_data/train_data.jsonl'),\n",
        "    n_exemplars=5,\n",
        "    random_seed=PROMPTS_SET_SEED\n",
        "    )\n",
        "prompts.sample_prompts()\n",
        "inputs = FormattedInputs(prompts)\n",
        "\n",
        "\n",
        "# Build few-shot prompting subsample dataset\n",
        "# Number of data points = 100, number of paths ensembled = 10\n",
        "N_DATA_POINTS = 100\n",
        "N_PATHS = 10\n",
        "with open(Path('CoTResearch/GSM8K_data/test_data.jsonl')) as file:\n",
        "    lines = file.readlines()\n",
        "    np.random.seed(TEST_SPLIT_SEED)\n",
        "    data_points_indices = np.random.randint(0, len(lines), size=(N_DATA_POINTS, ))\n",
        "    for data_point_index in data_points_indices:\n",
        "        inputs.sample_input(lines[data_point_index])"
      ],
      "metadata": {
        "id": "96qpGyCqiVxV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(inputs.inputs[0])"
      ],
      "metadata": {
        "id": "-3swi37gjgrm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Объект answers_list хранит отформатированные ответы модели и истинные ответы"
      ],
      "metadata": {
        "id": "iXQ0FXMgb5aq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "answers_list = AnswersList()"
      ],
      "metadata": {
        "id": "k0l88-4xl9ja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "В Hugging Face Inference API использую аналогичную модель BLOOM 176B и свой токен для использования http API моделей "
      ],
      "metadata": {
        "id": "tgpfqBMzcDig"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = \"bloom\"\n",
        "API_URL = f\"https://api-inference.huggingface.co/models/bigscience/{MODEL_NAME}\"\n",
        "HEADERS = {\"Authorization\": \"Bearer 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\"}\n",
        "\n",
        "\n",
        "def query(payload):\n",
        "    response = requests.post(API_URL, headers=HEADERS, json=payload)\n",
        "    return response.json()"
      ],
      "metadata": {
        "id": "xU8E9ufuC07q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Цикл получения генераций по всему тестовому набору данных при помощи сформированных входов. Для каждого входа генерирую несколько вариантов, чтобы в дальнейшем агрегировать."
      ],
      "metadata": {
        "id": "jn8JRl_PcaMN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# self-consistency chain of though prompting\n",
        "for i in tqdm(range(N_DATA_POINTS)):\n",
        "    prompt = inputs.inputs[i]\n",
        "    gt_answer = inputs.ground_truths[i]\n",
        "    predictions = []\n",
        "    paths_completed = 0\n",
        "    while paths_completed < N_PATHS:\n",
        "        time.sleep(5)\n",
        "        try:\n",
        "            output = query(\n",
        "                payload={\n",
        "                    \"inputs\": prompt.strip(),\n",
        "                    \"parameters\": {\n",
        "                        \"top_k\": 30,\n",
        "                        \"top_p\": None,\n",
        "                        \"temperature\": 0.2,\n",
        "                        \"repetition_penalty\": None,\n",
        "                        \"max_new_tokens\": 249,\n",
        "                        \"max_time\": None,\n",
        "                        \"return_full_text\": False,\n",
        "                        \"num_return_sequences\": 1,\n",
        "                        \"do_sample\": True,\n",
        "                        \"stop\": [\"Q:\", \"\\n\\n\"]\n",
        "                    },\n",
        "                    \"options\": {\n",
        "                        \"use_cache\": False,\n",
        "                        \"wait_for_model\": True\n",
        "                    }\n",
        "                }\n",
        "            )\n",
        "            predictions.append(output[0][\"generated_text\"])\n",
        "            print(output)\n",
        "        except Exception as e:\n",
        "            print(f'Exception occured on iteration {i}/{[paths_completed]}...{e}')\n",
        "            continue\n",
        "        else:\n",
        "            paths_completed += 1\n",
        "    answers_list.add_answer(predictions, gt_answer)\n",
        "    if i % 10 == 0:\n",
        "        answers_list.write_to_file(f'./drive/MyDrive/{PROMPTS_SET_SEED}_ensemble10_30_02.jsonl')\n",
        "    print('\\n')\n",
        "\n",
        "answers_list.write_to_file(f'./drive/MyDrive/{PROMPTS_SET_SEED}_ensemble10_30_02.jsonl')"
      ],
      "metadata": {
        "id": "sCMy29OmH0TV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Цикл получения генераций по всему тестовому набору данных при помощи сформированных prompts и сэмплирования с агрегацией. Использование petals distributed"
      ],
      "metadata": {
        "id": "T9GE8kMB-nKw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in tqdm(range(N_DATA_POINTS)):\n",
        "    prompt = inputs.inputs[i]\n",
        "    gt_answer = inputs.ground_truths[i]\n",
        "    tokenized_prompt = tokenizer(prompt, return_tensors=\"pt\")[\"input_ids\"].to(DEVICE)\n",
        "    predictions = []\n",
        "    for j in range(N_PATHS):\n",
        "        outputs = model.generate(\n",
        "            tokenized_prompt,\n",
        "            max_new_tokens=128,\n",
        "            return_full_text=False,\n",
        "            stop=['\\n\\n', 'Q:'],\n",
        "            # num_return_sequences=1  # number of paths for ansembling\n",
        "        )\n",
        "        predicted_answer = tokenizer.decode(\n",
        "            outputs[0],\n",
        "            # truncate_before_pattern=[r'\\n\\n', r'Q:']\n",
        "        )\n",
        "        predictions.append(predicted_answer)\n",
        "    answers_list.add_answer(predictions, gt_answer)"
      ],
      "metadata": {
        "id": "q2l_7tb-PTP3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Анализ полученных результатов"
      ],
      "metadata": {
        "id": "-iv-sxS6Umdf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls './CoTResearch/experiments/ensemble_results'"
      ],
      "metadata": {
        "id": "0hYYC7qjVchh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_result(filepath: str):\n",
        "    with open(filepath) as f:\n",
        "        return [json.loads(line) for line in f.readlines()]\n",
        "\n",
        "\n",
        "ensemble_result1 = AnswersList(extract_result('./CoTResearch/experiments/ensemble_results/12345_ensemble5_50_06.jsonl'))\n",
        "ensemble_result2 = AnswersList(extract_result('./CoTResearch/experiments/ensemble_results/14799_ensemble10_30_02.jsonl'))\n",
        "ensemble_result3 = AnswersList(extract_result('./CoTResearch/experiments/ensemble_results/77777_ensemble10_40_015.jsonl'))\n",
        "ensemble_result4 = AnswersList(extract_result('./CoTResearch/experiments/ensemble_results/77777_ensemble5_40_085.jsonl'))\n",
        "ensemble_results_list = [ensemble_result1, ensemble_result2, ensemble_result3,\n",
        "                         ensemble_result4]"
      ],
      "metadata": {
        "id": "BInC2G41ua_E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ensemble_results_acc = list(map(lambda x: x.calculate_accuracy(), ensemble_results_list))\n",
        "ensemble_results_mean = np.mean(ensemble_results_acc)\n",
        "ensemble_results_std = np.std(ensemble_results_acc)\n",
        "print('Среднее значение accuracy:', ensemble_results_mean)\n",
        "print('Стандартное отклонение accuracy:', ensemble_results_std)\n",
        "print(ensemble_results_acc)"
      ],
      "metadata": {
        "id": "3vXKdVJ6Uigl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 9))\n",
        "plt.bar(0, ensemble_results_acc[0], label='5 paths | top_k=50 | T=0.6', color='forestgreen')\n",
        "plt.bar(1, ensemble_results_acc[1], label='10 paths | top_k=30 | T=0.2', color='limegreen')\n",
        "plt.bar(2, ensemble_results_acc[2], label='10 paths | top_k=40 | T=0.15', color='turquoise')\n",
        "plt.bar(3, ensemble_results_acc[3], label='5 paths | top_k=40 | T=0.85', color='mediumseagreen')\n",
        "plt.xticks(range(len(ensemble_results_acc)), labels=['12345', '14799', '77777', '77777'])\n",
        "plt.ylim((0, 0.25))\n",
        "plt.xlabel('random seed')\n",
        "plt.ylabel('Test accuracy')\n",
        "plt.legend();"
      ],
      "metadata": {
        "id": "OR2k3_obUii3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def atleast_one(answers_list_object: AnswersList) -> int:\n",
        "    '''Хотя бы одно вхождение правильного ответа в ансамблевый выход'''\n",
        "    correct = 0\n",
        "    for item in answers_list_object:\n",
        "        gt = item['ground_truth']\n",
        "        preds = item['predicted']\n",
        "        if gt in preds:\n",
        "            correct += 1\n",
        "        else:\n",
        "            try:\n",
        "                gt = float(gt)\n",
        "                for pred in preds:\n",
        "                    pred = float(pred)\n",
        "                    if abs(gt - pred) < 0.01:\n",
        "                        correct += 1\n",
        "                        break\n",
        "            except:\n",
        "                continue   \n",
        "    return correct"
      ],
      "metadata": {
        "id": "VbkALljpYpp4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "errors_analysis_df = pd.DataFrame(\n",
        "    data=[[14, 5],\n",
        "          [17, 10],\n",
        "          [19, 10],\n",
        "          [15, 5]],\n",
        "    index=pd.Series(['12345', '14799', '77777', '77777'], name='random seed'),\n",
        "    columns=['Корректные', 'Количество сгенерированных \\'размышлений\\' для ансамблирования']\n",
        ")\n",
        "atleast_array = np.array([atleast_one(ensemble_result1), atleast_one(ensemble_result2), atleast_one(ensemble_result3), atleast_one(ensemble_result4)])\n",
        "errors_analysis_df['Количество CoT в одном prompt'] = 5\n",
        "errors_analysis_df['Хотя бы один правильный'] = atleast_array\n",
        "errors_analysis_df['Всего'] = 100\n",
        "errors_analysis_df"
      ],
      "metadata": {
        "id": "yySkeSGEUild"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4oT5K8aEUin8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}